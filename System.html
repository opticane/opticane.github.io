<!DOCTYPE html>
<html style="font-size: 16px;" lang="en-GB">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <meta name="keywords" content="writing courses, About our students, Online Writing Classes,Learning, and Community, 01, 02, 03, 04, How to Describe Nature, Questions?&nbsp;Comments?">
    <meta name="description" content="">
    <meta name="page_type" content="np-template-header-footer-from-plugin">
    <title>System</title>
    <link rel="stylesheet" href="nicepage.css" media="screen">
<link rel="stylesheet" href="System.css" media="screen">
    <script class="u-script" type="text/javascript" src="jquery.js" defer=""></script>
    <script class="u-script" type="text/javascript" src="nicepage.js" defer=""></script>
    <meta name="generator" content="Nicepage 3.10.2, nicepage.com">
    <link rel="icon" href="images/favicon1.png">
    <link id="u-theme-google-font" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:100,100i,200,200i,300,300i,400,400i,500,500i,600,600i,700,700i,800,800i,900,900i|Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i">
    
    
    
    
    
    
    
    
    
    
    
    
    <script type="application/ld+json">{
		"@context": "http://schema.org",
		"@type": "Organization",
		"name": "Opticane",
		"url": "index.html",
		"logo": "images/logo.png"
}</script>
    <meta property="og:title" content="System">
    <meta property="og:type" content="website">
    <meta name="theme-color" content="#478ac9">
    <link rel="canonical" href="index.html">
    <meta property="og:url" content="index.html">
  </head>
  <body class="u-body"><header class="u-clearfix u-header u-palette-1-dark-2 u-header" id="sec-af5e"><div class="u-clearfix u-sheet u-valign-middle-xs u-sheet-1">
        <a href="Opticane.html" data-page-id="71635948" class="u-image u-logo u-image-1" data-image-width="256" data-image-height="256" title="Opticane">
          <img src="images/logo.png" class="u-logo-image u-logo-image-1" data-image-width="64">
        </a>
        <nav class="u-menu u-menu-dropdown u-offcanvas u-menu-1">
          <div class="menu-collapse" style="font-size: 1rem; letter-spacing: 0px;">
            <a class="u-button-style u-custom-active-color u-custom-color u-custom-left-right-menu-spacing u-custom-padding-bottom u-custom-text-active-color u-custom-text-color u-custom-text-decoration u-custom-text-hover-color u-custom-top-bottom-menu-spacing u-nav-link u-text-active-palette-1-base u-text-hover-palette-2-base" href="#">
              <svg><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#menu-hamburger"></use></svg>
              <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><symbol id="menu-hamburger" viewBox="0 0 16 16" style="width: 16px; height: 16px;"><rect y="1" width="16" height="2"></rect><rect y="7" width="16" height="2"></rect><rect y="13" width="16" height="2"></rect>
</symbol>
</defs></svg>
            </a>
          </div>
          <div class="u-custom-menu u-nav-container">
            <ul class="u-nav u-unstyled u-nav-1"><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-light-1 u-text-hover-palette-1-light-1 u-text-white" href="Opticane.html" style="padding: 10px 20px;">Home</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-light-1 u-text-hover-palette-1-light-1 u-text-white" href="System.html" style="padding: 10px 20px;">System</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-light-1 u-text-hover-palette-1-light-1 u-text-white" href="Market.html" style="padding: 10px 20px;">Market</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-light-1 u-text-hover-palette-1-light-1 u-text-white" href="Evaluation.html" style="padding: 10px 20px;">Evaluation</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-light-1 u-text-hover-palette-1-light-1 u-text-white" href="About.html" style="padding: 10px 20px;">About</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link u-text-active-palette-1-light-1 u-text-hover-palette-1-light-1 u-text-white" href="References.html" style="padding: 10px 20px;">References</a>
</li></ul>
          </div>
          <div class="u-custom-menu u-nav-container-collapse">
            <div class="u-black u-container-style u-inner-container-layout u-opacity u-opacity-95 u-sidenav">
              <div class="u-sidenav-overflow">
                <div class="u-menu-close"></div>
                <ul class="u-align-center u-nav u-popupmenu-items u-unstyled u-nav-2"><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Opticane.html" style="padding: 10px 20px;">Home</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="System.html" style="padding: 10px 20px;">System</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Market.html" style="padding: 10px 20px;">Market</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="Evaluation.html" style="padding: 10px 20px;">Evaluation</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="About.html" style="padding: 10px 20px;">About</a>
</li><li class="u-nav-item"><a class="u-button-style u-nav-link" href="References.html" style="padding: 10px 20px;">References</a>
</li></ul>
              </div>
            </div>
            <div class="u-black u-menu-overlay u-opacity u-opacity-70"></div>
          </div>
        </nav>
      </div></header>
    <section class="u-clearfix u-palette-1-dark-3 u-section-1" id="carousel_07b4">
      <div class="u-clearfix u-sheet u-valign-middle-xs u-sheet-1">
        <h1 class="u-text u-text-1">System &amp; How it Works</h1>
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-2" id="sec-975d">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">System</h2>
        <p class="u-text u-text-2">Opticane's uses a LIDAR on a servo to control its LIDAR capabilities for a 180° field of view. It uses an LED to allow people to know of your presence in dark areas, uses a small microphone for voice commands, and five mini disc vibration motors for haptic feedback, where each motor makes direct contact with each one of your fingers. These components are then all combined together using a Raspberry Pi Zero powered by a rechargeable battery.<br>
          <br>Currently, these components are all housed in custom 3D printed parts, but in the future we would like to move to a rubber handle to negate any cross-vibrations as well as use a lighter carbon fiber material for the cane to decrease the overall weight.<br>
        </p>
        <img src="images/system-overview.png" alt="" class="u-border-5 u-border-palette-1-light-2 u-image u-image-default u-image-1" data-image-width="1235" data-image-height="1600">
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-3" id="sec-09e0">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-subtitle u-text u-text-1">LIDAR</h2>
        <p class="u-text u-text-2">Many smart canes in the market use SONAR or ultrasound technology. These systems can generate a lot of noise when in use and SONAR has issues detecting objects with smooth surfaces. Given a lot of buildings are made with sleek glass and metal this can be an issue for such canes in modern cities. That’s why at Opticane we decided to use LIDAR technology to remove these issues and allow for quiet and discreet operation of the cane.<br>
          <br>The LIDAR we have chosen to use is the <span class="u-text-palette-1-light-2">Benewake TF Luna LIDAR</span>, advertised as the world’s smallest LIDAR. This allows it to be mounted non-intrusively onto the cane and with a maximum reach of up to 8m it allows it to detect most objects in a user's vicinity. In order to rotate the LIDAR to give it a full 180 degree field of vision, the LIDAR is mounted to a <span class="u-text-palette-1-light-2">MG90S mini servo motor</span>. The motor’s small size allows it to be fitted discreetly under the LIDAR to provide all the functionality but still give the cane a sleek look.<br>
        </p>
        <img src="images/lidar.png" alt="" class="u-image u-image-default u-image-1" data-image-width="1920" data-image-height="1080">
        <p class="u-text u-text-3">We developed a simple but effective algorithm to partition and process the LIDAR data. The algorithm takes in all 180 LIDAR readings from its field of vision then segments that data into 5 partitions. These partitions represent the left, front left, front, front right and right of the user. Then for each partition we find the 3 closest distance readings in that partition and take the weighted average of them, with the closer the distance the greater the weighting. This weighting also disregards distances less than 0.2m since these readings are unreliable. This all allows for our readings to account for potential noise in the LIDAR.</p>
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-4" id="carousel_7140">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">Haptic Feedback</h2>
        <p class="u-text u-text-2">Haptic feedback is the main form of output for Opticane. Five mini disc vibration motors located in the grooves of the handle give comfortable access and an intuitive feel to the haptic feedback. With these motors, we have our own primitive haptic language that we like to call <span class="u-text-palette-1-light-2">Vibraille <span class="u-text-white"> where intensity, sharpness, and interval are varied to generate messages</span>
          </span>.<br>
          <br>Five average distances in each partition, calculated from LIDAR data, are translated to vibration feedback levels. The closer the distance the greater the vibration. These vibrations are then sent to the multiplexor which is in turn sent to the corresponding mini disc motor. The vibration felt for distance information is a short 'click' given at constant intervals.<br>
          <br>However, <span class="u-text-palette-1-light-2">Vibraille</span> is not just reserved for obstacle distance information. Battery Life Indication uses Vibraille by vibrating a number of motors - the more motors vibrating the less battery is left. We decided to go with 'more motors equals less battery' as research shows more haptics implies more alertness in the user and you want to alert the user more when the battery is low. The vibration itself is a strong pulse like a heartbeat and when the user feels five of these heartbeat vibrations they know the battery is at a critically low level.<br>
          <br>Each vibration motor also has a small bump on it to indicate which direction the motor corresponds to with haptic feedback. This can be changed to braille in the future.<br>
        </p>
        <img src="images/haptic-feedback.png" alt="" class="u-border-5 u-border-palette-1-light-2 u-image u-image-default u-image-1" data-image-width="1448" data-image-height="1424">
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-5" id="carousel_bc9d">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">Low Light LED</h2>
        <p class="u-text u-text-2">A big issue facing visually impaired users is travelling at night. Unlike sighted people, the visually imapired people have trouble making themselves more visible to pedestrians, cyclists, etc. [10] We decided to add a feature to our cane where if the LIDAR detects low light an LED will turn on bringing more visibility to the user. The LIDAR detects low light through its 'Amp' value- if the amp value (signal strength) is less than 100 the signal is underexposed and therefore the environment is dark.<br>
          <br>We also decided to go with a soft warm light LED as well, to prevent pedestrians etc being dazzled by a brighter LED light.<br>
        </p>
        <img src="images/led.png" alt="" class="u-image u-image-default u-image-1" data-image-width="1600" data-image-height="900">
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-6" id="carousel_f8d6">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">Speech Recognition</h2>
        <p class="u-text u-text-2">Opticane understands voice commands for checking battery levels and navigation. This is implemented in Python through its SpeechRecognition library and uses CMU Sphinx Speech Recognition Engine for offline speech recognition. [11]<br>
          <br>The basic commands we have implemented so far include:
        </p>
        <div class="u-table u-table-responsive u-table-1">
          <table class="u-table-entity">
            <colgroup>
              <col width="23%">
              <col width="77%">
            </colgroup>
            <thead class="u-palette-1-base u-table-header u-table-header-1">
              <tr style="height: 42px;">
                <th class="u-border-1 u-border-palette-1-light-1 u-table-cell">Command</th>
                <th class="u-border-1 u-border-palette-1-light-1 u-table-cell">Description</th>
              </tr>
            </thead>
            <tbody class="u-table-body">
              <tr style="height: 65px;">
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Check Battery Life</td>
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Engages the aforementioned haptic feedback mode to show the user how much battery is left via vibration</td>
              </tr>
              <tr style="height: 65px;">
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Save location as <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>
                </td>
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Saves the longitude and latitude of a named location, <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>, to Opticane’s system
                </td>
              </tr>
              <tr style="height: 65px;">
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Where is <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>?
                </td>
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Retrieves the longitude and latitude of the named location, <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>, and calculates directions based on the current location of the user
                </td>
              </tr>
              <tr style="height: 42px;">
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Delete <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>
                </td>
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Deletes the named location, <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>, from Opticane’s system
                </td>
              </tr>
              <tr style="height: 65px;">
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Stop Navigation</td>
                <td class="u-border-1 u-border-grey-dark-1 u-table-cell">Stops the haptic feedback navigation which is providing haptic directions to get to a saved location.</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-7" id="carousel_7394">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">Haptic Navigation</h2>
        <p class="u-text u-text-2">Navigation is a huge issue for the visually blind. Jack Loomis from the University of California Santa Barbara points this out in a paper discussing the issue saying how "visually impaired people do not have the benefit of recognising landmarks, buildings etc as an indication of location." [12] Additionally voice-based map technologies such as Google Maps are limited in the number of cities and are mostly English based. We therefore proposed an additional feature where users can receive navigation information to get to a specified location via a Haptic Feedback while removing the issue of translation voice-based maps have.<br>
          <br>The Haptic Navigation works through a combination of the aforementioned speech recognition and Opticane’s GPS module. The GPS module is attached to Opticane’s Raspberry Pi and can receive longitude and latitude data of the user’s current location. If the user wants directions to return to a location, they can use the "Save location as <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>" to save the longitude and latitude of the current location with an associated name to the Opticane’s system.<br>
          <br>This location can then be recalled with the "Where is <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>?" where Opticane’s system recalls the named location <span class="u-text-palette-1-light-2">&lt;Location&gt;</span>, retrieves the longitude and latitude of said location and using the current longitude and latitude calculates the direction the user needs to go in.<br>
          <br>The Haptic Motors that correspond to the directions the user should take are similar to obstacle detection mapping: middle and index finger means right, ring and pinky means left, and thumb means forward.<br>
          <br>Since, unlike the battery life haptics, the navigation haptics have to be differentiated from the obstacle detection haptics in order to not confuse the user. As a result, we use a different vibration pattern for navigation than obstacle detection: a soft double tick 'burst' of vibration in longer intervals to regularly remind the user of the direction.<br>
        </p>
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-8" id="carousel_d118">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">Battery Life</h2>
        <p class="u-text u-text-2">A long lasting battery life was essential to the design of our product. After all, we wouldn’t want to inhibit our users by forcing them to recharge the cane every few hours.<br>
          <br>Assuming every aspect of the device is on at all times, i.e. motors constantly going off at full power, we can calculate an Lower Bound on the battery life via an Upper Bound on the current draw.<br>
        </p>
        <p class="u-align-left u-small-text u-text u-text-variant u-text-3">
          <span style="font-style: normal;">Upper bound on Current Draw: 70mA (LiDAR) + 375mA (MiniDisc Motors) + 120mA (Servo Motor) + 20mA (Pi Zero) = <span class="u-text-palette-1-light-2">580mA</span>
            <br>
            <br>Battery Consumption = 1800mAh/580mA = <span class="u-text-palette-1-light-2">~3.1 hours of battery life</span>
          </span>
        </p>
        <p class="u-text u-text-4">However this is unrealistic as to how the product operates. From studying the video of the servo motor, it takes 1.5 seconds to complete its rotation and for the Pi to buffer all LiDAR data. However sources indicate that the actual motor time for such an operation is 0.3s. [13] So the motor is only drawing 120mA 20% of the time, the other 80% it is idle waiting for LiDAR data to be processed. At this stage it will only draw 10mA. The MiniDisc Motors will also not constantly draw their 75mA maximum, the average terminal output shows the miniDisc motors are usually not all engaged at once and maybe only one or two are showing any reading at one time. So you could take an average 80mA (say one motor is operating at mid level 20mA and another at high level 60mA)<br>
          <br>Therefore we can now accurately construct a more realistic battery life consumption.<br>
        </p>
        <p class="u-align-left u-small-text u-text u-text-variant u-text-5">Total Current Draw: 70mA (LIDAR) + 80mA (MiniDisc Motors) + (120*0.2+10*0.8)mA (Servo Motor) + 20mA (Pi Zero) = <span class="u-text-palette-1-light-2">202mA</span>
          <br>
          <br>Battery Consumption = 1800mAh/202mA = <span class="u-text-palette-1-light-2">~8.91 hours of battery life</span>
          <br>
        </p>
        <p class="u-text u-text-6">Therefore with the current battery, Opticane can reach almost a full working day of battery life. There are no concerns if you go out in the morning of Opticane dying before you get back in the evening.<br>
          <br>While this battery life is good, in the future Opticane would look at getting a better battery for the cane. For example the <span class="u-text-palette-1-light-2">Xenta Power Bank<span class="u-text-white"> &nbsp;</span>
          </span>can power our Upper Bound on current draw, 580mA, for up to 18 hours. However the weight of such a battery at 180g, would also need to be factored into the design of our cane, which we are trying to keep as lightweight as possible. Battery life vs portability is a classic engineering issue that through further research experimentation we would try to resolve.<br>
        </p>
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-9" id="carousel_5142">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">Weight</h2>
        <p class="u-text u-text-2">For our final hardware prototype of the cane, we’ve endeavoured to find the smallest and lightest hardware components possible that still allow for the same level of functionality. In a 2013 study, it was found that lighter canes made of carbon fibre (around 113g) did not strain the wrist and upper muscles as much as conventional canes weighing around 252g- “results indicated that the newly developed cane reduced the loads on muscles by approximately 50%. This is why in the final product, we looked into a lighter carbon-fibre cane that could be used. Additionally it gives us parameters to work with in terms of 252g is the acceptable cane weight so we should select parts for the cane handle to ensure the combined weight of the carbon fibre cane and the handle is less than 252g.<br>
          <br>In the final prototype we did use a slightly heavier casing made of plastic material for the handle and other parts. So the total weight for the prototype is:<br>
        </p>
        <p class="u-align-left u-small-text u-text u-text-variant u-text-3">Total Weight: 182g (cane + handle + casing) + 14g (servo motor) +9g (Raspberry Pi) + 21g (battery) +5g (LIDAR) = <span class="u-text-palette-1-light-2">231g</span>
          <br>
        </p>
        <p class="u-text u-text-4">However in the actual product we would use a lighter cane made of carbon fibre, around 113g, plus a lighter rubber mould which we estimate is around 20g. Therefore the total weight of the final product would be around 182g.&nbsp;<br>
        </p>
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-10" id="carousel_25ba">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">Prototype</h2>
        <p class="u-text u-text-2">To demonstrate the feasibility of Opticane, we 3D modeled and printed the parts for a minimum working prototype. This included printing the handle, a portion of the cane, a custom piece to secure our LIDAR to the servo, and the LIDAR casing. Afterwards, the technician team fitted the vibration motors, Raspberry Pi, battery, servo, and LIDAR into their respective casings to create a working prototype that could perform accurate object detection.&nbsp;<br>
        </p>
        <img src="images/prototype.jpg" alt="" class="u-image u-image-default u-image-1" data-image-width="1600" data-image-height="900">
      </div>
    </section>
    <section class="u-clearfix u-palette-1-dark-3 u-section-11" id="carousel_c909">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-heading-font u-subtitle u-text u-text-1">Simulation</h2>
        <p class="u-text u-text-2">In addition to our prototype, to demonstrate the more technically complex aspects of Opticane, we used a Webots simulation. In this simulation, we have modeled human controllers swinging a LIDAR-mounted cane from side to side and reacting to object detection values received from the LIDAR. The simulation also uses keyboard input to activate voice commands and successfully presents Opticane's haptic navigation system and battery checking capabilities.<br>
          <br>With the simulation, we were able to more easily illustrate and understand the possible use cases of Opticane in real world scenarios with all of its technical complexities. It also allowed us to perform pseudo-user testing which was very beneficial given the restraints of the pandemic.&nbsp;<br>
        </p>
        <img src="images/simulation.jpeg" alt="" class="u-image u-image-default u-image-1" data-image-width="1920" data-image-height="996">
      </div>
    </section>
    
    
    <footer class="u-align-center u-clearfix u-footer u-grey-80 u-footer" id="sec-ebc1"><div class="u-clearfix u-sheet u-sheet-1">
        <p class="u-align-left u-small-text u-text u-text-variant u-text-1">© 2021 Opticane, Inc.</p>
      </div></footer><span style="height: 64px; width: 64px; margin-left: 0px; margin-right: auto; margin-top: 0px; background-image: none; right: 20px; bottom: 20px" class="u-back-to-top u-icon u-icon-circle u-opacity u-opacity-85 u-palette-1-base u-spacing-15" data-href="#">
        <svg class="u-svg-link" preserveAspectRatio="xMidYMin slice" viewBox="0 0 551.13 551.13"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#svg-1d98"></use></svg>
        <svg class="u-svg-content" enable-background="new 0 0 551.13 551.13" viewBox="0 0 551.13 551.13" xmlns="http://www.w3.org/2000/svg" id="svg-1d98"><path d="m275.565 189.451 223.897 223.897h51.668l-275.565-275.565-275.565 275.565h51.668z"></path></svg>
    </span>
  </body>
</html>